---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---


# DATA MINING PHASE 2 

##### importing needed packages
```{r}
library(stringr)
library(tidyr)
library(data.table)

library(dplyr)

install.packages("outliers")
library(outliers)

install.packages("ggplot2")
library(ggplot2)

library(tidyverse)
library(plotly)
```


##### dataset importing
```{r}
library(readxl)
dataset <- read_excel("C:/Users/Royna/Desktop/laptop_price.xlsx")
View(dataset)
```


### Raw data set
```{r}
# Display the first 10 rows
head(dataset, 10)

# Display the last 10 rows
tail(dataset, 10)
```

### Missing values

##### There are no missing values in our dataset
```{r}
#check for missing values
sum(is.na(dataset))
```


##### We replaced the ID attribute in the raw dataset to make sure that the ID indicates each row uniquely.
```{r}
#delete laptop_ID attribute
dataset <- dataset[, -which(names(dataset) == "laptop_ID")]

# making ID coloum
row_numbers <- data.frame(ID = 1:nrow(dataset))
row_numbers$ID <- as.character(row_numbers$ID)
dataset$ID <- row_numbers$ID
dataset <- dataset[, c("ID", names(dataset)[-ncol(dataset)])]
```

##### We convert Weight attribute from char to numeric by removing the "kg" suffix to apply any needed mathematical operations.
```{r}
#sub the kg from Weight attribute
dataset$Weight <- gsub("kg", "", dataset$Weight)
#convert Weight to numeric
dataset$Weight<- as.numeric(as.character(dataset$Weight))

```

### Outlier Analysis

#### Detecting outliers

##### We used boxplot graph to indicate the outliers than compared them to the maximum value, we noticed that not all the outlier rows are actually outliers, for example the row with ID 191 is only 3 euros higher from the maximum value, so it was identified as an outlier.
##### We also used z-score method to indicate extreme values from the mean, We compared the two methods and all the z-score results matches the outliers detected in the boxplot. We also went through the rows manually and all z-score results were logical.
```{r}
#-------boxplot --------
#-------outliers--------


bp <- boxplot(dataset$Price_euros)
mean_price <- mean(dataset$Price_euros)
median_values <- bp$stats[3]
lower_quartile <- bp$stats[2]
upper_quartile <- bp$stats[4]
outliers <- bp$out
outliers <- outliers[order(outliers)]


cat("Median:", median_values, "\n")
cat("Lower Quartile (Q1):", lower_quartile, "\n")
cat("Mean Price (euros):", mean_price, "\n")
cat("Upper Quartile (Q3):", upper_quartile, "\n")

# rows with outliers
outlier_indices <- dataset$Price_euros %in% outliers
# only rows with outliers
outliers_data <- dataset[outlier_indices, c("ID", "Price_euros")]

# analyze price outliers
outliers_data$differenceFromMAx <- outliers_data$Price_euros - 2821

# Calculate standard deviation
sd_price <- sd(dataset$Price_euros)

# z score for outliers
z_scores <- (dataset$Price_euros - mean_price) / sd_price
threshold <- 3

```

#### Removing outliers

##### We used the z-score results to delete the outliers, because it was more logical than the boxplot results.
```{r}
# Create a new dataset containing outliers
deleted_Outliers <- dataset[abs(z_scores) > threshold, ]

#deleting outliers
dataset <- anti_join(dataset, deleted_Outliers, by = "ID")
row_numbers <- data.frame(ID = 1:nrow(dataset))
row_numbers$ID <- as.character(row_numbers$ID)
dataset$ID <- row_numbers$ID

#boxplot after removing outliers
bp <- boxplot(dataset$Price_euros)
# +++++median now is in the middle+++++
mean_price <- mean(dataset$Price_euros)
median_values <- bp$stats[3]
lower_quartile <- bp$stats[2]
upper_quartile <- bp$stats[4]

cat("Median:", median_values, "\n")
cat("Lower Quartile (Q1):", lower_quartile, "\n")
cat("Mean Price (euros):", mean_price, "\n")
cat("Upper Quartile (Q3):", upper_quartile, "\n")


```

### Statstical Summaries

##### This function provides insights into the central tendency of the data through measures like mean and median. offering a sense of the data’s central location.you can notice the mean of the Price_euros is 1095.4,for the Inches it is 15,for the Weight its 2.025 ,the median for the Price_euros is 961.0  ,the median for the weight is 2.040  ,the median for the Inches is 15.6 The summary includes information about the spread of the data, providing the minimum and maximum values. This gives a sense of the range within which the data is distributed,for the Price_euros the range is between 174 and 3154 ,for the Weight it is between 0.690 and 4.600,for the Inches it is between 10.1 and 18.4.

##### The summary function provides quartiles, which, when combined with the median, help identify skewness or asymmetry in the data distribution.

##### For the Price_euros column the  Q1 < Q2 < Q3 it indicates it is  right-skewed (positively skewed) distribution.
##### For the weight column the  Q1 < Q2 < Q3 it indicates it is  right-skewed (positively skewed) distribution.
##### For the inches column the  Q1 < Q2 < Q3 it indicates it is  right-skewed (positively skewed) distribution.


```{r}
summary(dataset)
```

#### Find the mean of all data


##### Based on my observation of the dataset, the mean of the prices of laptops is 1095.413. Analyzing this can help consumers understand the overall pricing trend and make informed decisions based on their budget.
```{r}
#mean of laptop prices .
mean(dataset$Price_euros)
```


##### Based on my observation of the dataset, the mean of the laptop screen sizes measured in inches is 15.00116. Analyzing this can help consumers choose a suitable laptop based on their preferences for display dimensions and portability.
```{r}
#mean of laptop screen sizes in inches .
 
mean(dataset$Inches)
```


##### Based on my observation of the dataset, the mean of the weight of laptops is 2.025469 . interpreting this allows users to grasp the typical weight of available laptops, aiding consumers in choosing portable or robust device based on their needs.
```{r}
#mean of laptop weights .
mean(dataset$Weight)
```


#### Find median of all data


##### The median is 961,The median laptop price represents the middle point, offering a central value that helps consumers understand a typical price range.
```{r}
#median of laptop prices
median(dataset$Price_euros)
```


##### The median is "HP",The median of laptop companies signifies the middle point, providing insight into the industry's typical market positioning and competitiveness.
```{r}
#median of Company
median(dataset$Company)
```


##### "Legion Y520-15IKBN"   The median of laptop brands suggests the midpoint, aiding consumers in identifying a typical brand positioning within the market.
```{r}
#median of Product
median(dataset$Product)
```


##### "Notebook"  The median of laptop types reveals the midpoint, illustrating a typical classification representing consumer preferences and market distribution.
```{r}
#median of TypeName
median(dataset$TypeName)
```


##### 15.6  The median of laptop screen sizes offers a central point, aiding in understanding the typical display size available.
```{r}
#median of Inches
median(dataset$Inches)
```


##### "Full HD 1920x1080" The median of screen resolutions indicates a central value, reflecting a typical display quality preferred by laptop users.
```{r}
#median of Screen Resolution
median(dataset$ScreenResolution)
```


##### "Intel Core i5 7Y54 1.2GHz" The median of CPU (central processing unit) signifies a central performance level, representing a typical processing power preferred by users.
```{r}
#median of Cpu
median(dataset$Cpu) 
```


##### 2.04  The median of laptop weights gives a central weight value, aiding in identifying a typical weight range for laptops.
```{r}
#median of Weight
median(dataset$Weight)
```


##### "Windows 10"   The median of operating systems reflects the midpoint, showing a typical OS preference and market distribution for laptop users.
```{r}
#median of OpSys
median(dataset$OpSys)
```


##### "6GB"  The median of RAM size provides a central value, offering insight into the common memory capacity preferred by laptop users.
```{r}
#median of Ram
median(dataset$Ram)
```


##### "Intel HD Graphics 620" The median of GPU (graphics processing unit) denotes a central value, showcasing a typical level of graphics performance preferred by users.
```{r}
#median of Gpu
median(dataset$Gpu)
```


##### "256GB SSD" The median of memory capacity showcases a central value, offering insight into a typical storage preference among laptop users.
```{r}
#median of Memory
median(dataset$Memory)
```


#### Mode of data 


##### The mode is 2.2, it is the most common weight range in the market, revealing preferences and trends influencing consumer choices.
```{r}
Data_Set <- dataset
#mode of weight
names(sort(-table(Data_Set$Weight)))[1]
```


##### The mode is 1099,it indicates the most frequently occurring price range, providing insight into the market's preferred price points and consumer purchasing patterns.
```{r}
#mode of price
names(sort(-table(Data_Set$Price_euros)))[1]
```


##### The mode is 15.6, it reveals the most prevalent screen dimensions.
```{r}
#mode of screen size in inches
names(sort(-table(Data_Set$Inches)))[1]
```


##### The mode is "Dell", it highlights the most dominant brand.
```{r}
#mode of company
names(sort(-table(Data_Set$Company)))[1]
```


##### The mode is "XPS 13", it highlights the most dominant product.
```{r}
#mode of product
names(sort(-table(Data_Set$Product)))[1]
```


##### The mode is "Intel Core i5 7200U 2.5GHz", it reveals the most prevalent processors.
```{r}
#mode of cpu
names(sort(-table(Data_Set$Cpu)))[1]
```


##### The mode is "8GB", it identifies the most common memory capacity.
```{r}
#mode of ram
names(sort(-table(Data_Set$Ram)))[1]
```


##### The mode is "Windows 10", it highlights the most dominant opertion system.
```{r}
#mode of operating system
names(sort(-table(Data_Set$OpSys)))[1]
```



#### Find the range for all data

##### the lowest price of laptop is  174, and the highest price is 3154 so the range equals (3154-174=2980). The range suggests diverse pricing options, catering to varying budgets . 
```{r}
#range of laptop prices .
range(dataset$Price_euros)
```


##### the lowest of weight laptop is  0.69, and the highest weight is 4.60. the range suggests a diverse array of laptop weights, understanding this range aids consumers in selecting a laptop that aligns with their mobility needs considering factors like portability and ease of use.
```{r}
#range of laptop weights . 
range(dataset$Weight)
```


##### the lowest oflaptop screen size is 10.1,and the highest is  18.4. so whether you prefer a compact and portable laptop or a larger screen ,there is plenty of options available within the range.
```{r}
#range of laptop screen sizes in inches .
range(dataset$Inches)
```



#### Covariance 

##### the covariance between price and weight 58.94169, since its positive it suggests that as price increases, weight tends to increase as well. However, the magnitude of the covariance doesnt provide a clear indication of the strength of relationshop.
```{r}
#Covariance of Price_euros and Weight
cov(dataset$Price_euros,dataset$Weight)
```


##### the covariance between price and screen size in inches is 17.49397, A positive covariance suggests that as screen size increases, the price tends to rise.
```{r}
#Covariance of Price_euros and Inches
cov(dataset$Price_euros,dataset$Inches)
```


#### Calculating the variance for numeric data

##### The variance is 399382.9, the variance for laptop prices reveals significant variations among different Company, operation system , and Ram size,etc.
```{r}
#variance of Price_euros
var(dataset$Price_euros)
```


##### The variance is 0.4207763,The low variance in laptop weights indicates consistent weight patterns across various models.
```{r}
#variance of Weight
var(dataset$Weight)
```


##### The variance is 2.015324,A low variance in laptop screen sizes suggests a standardized trend among models. 
```{r}
#variance of Inches 
var(dataset$Inches)
```


#### Standard Deviation of numeric data


##### The standard deviation is 631.9674. The high standard deviation of laptop prices reveals the extent of price dispersion from the mean. A higher standard deviation signifies a wider price range, indicating more significant price variations. 
```{r}
#standard deviation of laptop prices 
sd(dataset$Price_euros)
```


##### The standard deviation is 0.6486727. A low standard deviation in laptop weights implies a minimal deviation from the mean weight, showcasing consistency in manufacturing.
```{r}
#standard deviation of weight
sd(dataset$Weight)
```


##### The standard deviation is 1.419621 . A low standard deviation in laptop screen sizes indicates a narrow range of variation around the mean,providing consumers with a predictable and standard selection of laptop displays across different models and brands.
```{r}
#standard deviation of screen size in inches 
sd(dataset$Inches)
```


##### Relationship between price of laptop and company
```{r}
ggplot(dataset,aes(Price_euros,Company))+geom_point()
```


##### Relationship between price of laptop and operating system
```{r}
ggplot(dataset,aes(Price_euros,OpSys))+geom_point()
```


##### Relationship between price of laptop and type of laptop
```{r}
ggplot(dataset,aes(Price_euros,TypeName))+geom_point()
```


##### Relationship between price of laptop and Ram
```{r}
ggplot(dataset,aes(Price_euros,Ram))+geom_point()
```


#### Finding the number of attributes, Observation, strucutre, statistical measures, etc..
```{r}
nrow(dataset)
ncol(dataset)
dim(dataset)
names(dataset)
str(dataset)
is.null(dataset)

```
```{r}
#detecting outliers
outliersInches <- boxplot.stats(dataset$Inches)$out
boxplot(dataset$Inches,
        ylab = "Inches",
        main = "Inches" )


outliersPrice_euros <- boxplot.stats(dataset$Price_euros)$out
boxplot(dataset$Price_euros,
        ylab = "Price_euros",
        main = "Price_euros" )
graphics.off()
x<- dataset
x<- x[-which(dataset$Inches%in% outliersInches),]
x<- x[-which(dataset$Price_euros%in% outliersPrice_euros),]

remove_outliers <- function(x, na.rm = TRUE, ...){
  qnt <- quantile(x, probs = c(.25, .75), na.rm=na.rm,...)
  H<- 1.5 *IQR(x, na.rm =na.rm)
  y<-x
  y[x< (qnt[1] -H)]<-NA
  y[x>qnt[2] +H]<- NA
  y
}
```

### Data Preproccesing


```{r}
#sum of missing value
sum(is.na(dataset))
```


```{r}
#Find unique values in Ram
unique(dataset$Ram)
```

##### We convert Ram attribute to numeric by removing the GB to apply any needed mathematical operations.
```{r}
#Encode the Ram attribute
dataset$Ram=factor(dataset$Ram,levels=c("8GB","16GB","4GB","2GB","12GB","6GB","32GB","24GB","64GB"),
                   labels=c("8","16","4","2","12","6","32","24","64"))
dataset$Ram<- as.numeric(as.character(dataset$Ram))

```



```{r}
#Find unique values in Weight
unique(dataset$Weight)
```

##### Encoding the Operating System so we can use it in future graphs.
```{r}
#unique opsy
unique(dataset$OpSys)
dataset$OpSys=factor(dataset$OpSys,levels=c("macOS","No OS","Windows 10","Mac OS X","Linux","Android","Windows 10 S","Chrome OS","Windows 7"),
                     labels=c(1,2,3,4,5,6,7,8,9))
```
```{r}
#Find unique values in CPU
unique(dataset$Cpu)
```


##### This step will add a new attribute that will categorize rows based on their price into one of the three categories: "cheap" "affordable" or "expensive".
```{r}
dataset$price=cut (dataset$Price_euros, breaks=c(150, 400, 1250, 3200), labels=c("cheap","affordable","expensive"))

```



### Data Splitting

#### Data splitting on CPU

##### CPU attribute is nominal and has 115 unique value, We could not use it until we categorized it into 10 values, we used the CPU brand and generation to categorize it. For "Intel Core i5" and "Intel Core i7", we noticed that they present more than 50% of the data, so we used the clock speed to categorize it further into CPUs with clock speed larger than 2 GHz or less. This step enabled us to generate usefull graphs out of this attribute.

##### You can notice from the graph that some CPU types can be described as  cheap (less than 400 €) like "AMD A-Series", "AMD E-Series", "Intel Atom x", "Intel Celeron", "Intel Core i3", and "Intel Pentium". We can also see that "Intel Core i5", "Intel Core i7", and "Intel Core M" has a large range of value, it can be described as "Affordable" or "Expensive".
```{r}
# categorizing CPU types
pattern_categories <- data.frame(
              Cpu = c("Intel Core i3 .*","Intel Core i5 .*", "Intel Core i7 .*", "Intel Core i9 .*",
                          "Intel Core M.*", "(?i)Intel Atom x.*",
                          "Intel Celeron .*","Intel Pentium .*",
                          "AMD A.*", "AMD E.*"),
              
                Category = c("Intel Core i3", "Intel Core i5", "Intel Core i7","Intel Core i9",
                             "Intel Core M", "Intel Atom x",
                             "Intel Celeron", "Intel Pentium", 
                             "AMD A-Series", "AMD E-Series")
  )

# Intel Atom X5-Z8350 1.44GHz was not categoried bc of X instead of x so I should correct it

# assigning categories based on patterns
assign_category <- function(Cpu) {
  for (i in 1:nrow(pattern_categories)) {
    if (grepl(pattern_categories$Cpu[i], Cpu)) {
      return(pattern_categories$Category[i])
    }
  }
  return("Other")  # if no patterns match, it assigns it to "Other"
}


#new column with categories
Cpu_Categories <- sapply(dataset$Cpu, assign_category)

#data frame with CPU names and categories
cpu_data <- data.frame(CPU_Name = dataset$Cpu, Category = Cpu_Categories)

# adding the category coloum to the dataset
dataset <- data.frame(ID = dataset$ID, Company = dataset$Company, Product = dataset$Product,
                  TypeName = dataset$TypeName, Inches = dataset$Inches, 
                  ScreenResolution = dataset$ScreenResolution, Cpu = dataset$Cpu,
                  Category = cpu_data$Category,Ram = dataset$Ram,
                  Memory = dataset$Memory, Gpu = dataset$Gpu, OpSys = dataset$OpSys, 
                  Weight = dataset$Weight, Price_euros = dataset$Price_euros
                  )

# Extract GHz from CPU names
dataset$categories <- as.numeric(gsub(".*?(\\d+\\.\\d+)GHz.*", "\\1", dataset$Cpu))

dataset$CategoryCPU <- dataset$Category

dataset$CategoryCPU <- ifelse(
  (dataset$Category == "Intel Core i7" | dataset$Category == "Intel Core i5") & dataset$categories <= 2,
  paste(dataset$Category, "<2", sep = " "), dataset$CategoryCPU
)

dataset$CategoryCPU <- ifelse(
  (dataset$Category == "Intel Core i7" | dataset$Category == "Intel Core i5") & dataset$categories > 2,
  paste(dataset$Category, ">2", sep = " "), dataset$CategoryCPU
)


# Plot dataset
ggplot(dataset, aes(x = CategoryCPU, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by CPU Type", x = "CPU Type", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```



#### Data splitting on GPU
##### GPU attribute is nominal and has 103 unique value, We could not use it until we categorized it into 7 values, we used the GPU brand and generation to categorize it. This step enabled us to generate usefull graphs out of this attribute.

##### We can notice that "AMD Radeon Graphics" and "Intel UHD Graphics" is in the cheaper range. For "Intel HD Graphics" and "Nvidia GeForce Graphics" we see that thier price range is large, they can be categorized as "Affordable" or "Expensive". As for "Intel Iris Graphics" and "Nvidia GeForce Graphics", they range above 1250, we can describe them as "Expensive".
```{r}

# Categorizing GPU types
gpu_pattern_categories <- data.frame(
  Gpu = c("Intel Iris.*", "Intel HD Graphics.*", "AMD Radeon.*", "Nvidia GeForce.*", "Intel UHD Graphics.*", "Nvidia Quadro .*"),
  Category = c("Intel Iris Graphics", "Intel HD Graphics", "AMD Radeon Graphics", "Nvidia GeForce Graphics", "Intel UHD Graphics", "Nvidia Quadro")
)

# Function to assign GPU categories based on patterns
assign_gpu_category <- function(gpu_name) {
  for (i in 1:nrow(gpu_pattern_categories)) {
    if (grepl(gpu_pattern_categories$Gpu[i], gpu_name)) {
      return(gpu_pattern_categories$Category[i])
    }
  }
  return("Other")  # Assign to "Other" category if no patterns match
}

# Create a new column "Gpu_Category"
dataset$CategoryGPU <- sapply(dataset$Gpu, assign_gpu_category)

#plot
ggplot(dataset, aes(x = CategoryGPU, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by GPU Category", x = "GPU Category", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

dataset <- dataset[, c("ID", "Company", "Product", "TypeName", "Inches", "ScreenResolution", "Cpu","CategoryCPU", "Ram", "Memory", "Gpu", "CategoryGPU", "OpSys", "Weight", "Price_euros")]

```



#### Data splitting on Memory
##### Since Memory attribute had more than one information, we split the Memory attribute into: Memory type, and memory size -where sizes unit is in GB- to show the effect of each information.

##### We can notice that "Flash Storage", "HDD", and "Hybrid" is in the cheaper range. "SSD has a large price range so it can be categorized as "cheap", "Affordable" or "Expensive".For "SSD&HDD" we see that its price range is large, it can be categorized as "Affordable" or "Expensive".

##### Memory sizes that are (16,32,64)GB can be categorized as "Cheap". For (500,1000)GB it can be described as "Cheap" or "Affordable". For (256,1024,1128)GB it can be categorized as "Affordable" or "Expensive". For (512,1256)GB it can be categorized as "Expensive".

```{r}
# categorizing Memory types
dataset$Memory=factor(dataset$Memory,levels=c("128GB SSD" ,  "128GB Flash Storage" ,         
                                              "256GB SSD" ,                    "512GB SSD",                    
                                              "500GB HDD",                     "256GB Flash Storage" ,         
                                              "1TB HDD",                       "32GB Flash Storage"  ,         
                                              "128GB SSD +  1TB HDD",          "256GB SSD +  256GB SSD",       
                                              "64GB Flash Storage",            "256GB SSD +  1TB HDD",         
                                              "256GB SSD +  2TB HDD" ,         "32GB SSD",                     
                                              "2TB HDD",                       "64GB SSD",                     
                                              "1.0TB Hybrid",                  "512GB SSD +  1TB HDD",         
                                              "1TB SSD" ,                      "256GB SSD +  500GB HDD",       
                                              "128GB SSD +  2TB HDD",          "512GB SSD +  512GB SSD",       
                                              "16GB SSD",                      "16GB Flash Storage",           
                                              "512GB SSD +  256GB SSD" ,       "512GB SSD +  2TB HDD",         
                                              "64GB Flash Storage +  1TB HDD", "180GB SSD",                    
                                              "1TB HDD +  1TB HDD" ,           "32GB HDD",                     
                                              "1TB SSD +  1TB HDD" ,           "512GB Flash Storage",          
                                              "128GB HDD",                     "240GB SSD",                    
                                              "8GB SSD",                       "508GB Hybrid",                 
                                              "1.0TB HDD",                     "512GB SSD +  1.0TB Hybrid",    
                                              "256GB SSD +  1.0TB Hybrid"),
                   labels=c("128GB SSD" ,  "128GB Flash Storage" ,         
                            "256GB SSD" ,                    "512GB SSD",                    
                            "500GB HDD",                     "256GB Flash Storage" ,         
                            "1000GB HDD",                       "32GB Flash Storage"  ,         
                            "1128GB SSD&HDD",          "512GB SSD  SSD",       
                            "64GB Flash Storage",            "1256GB SSD&HDD",         
                            "2256GB SSD HDD" ,         "32GB SSD",                     
                            "2000GB HDD",                       "64GB SSD",                     
                            "1000GB Hybrid",                  "1512GB SSD&HDD",         
                            "1000GB SSD" ,                      "756GB SSD&HDD",       
                            "2128GB SSD&HDD",          "1024GB SSD",       
                            "16GB SSD",                      "16GB Flash Storage",           
                            "768GB SSD" ,       "2512GB SSD&HDD",         
                            "164GB Flash Storage HDD", "180GB SSD",                    
                            "2000GB HDD" ,           "32GB HDD",                     
                            "2000GB SSD&HDD" ,           "512GB Flash Storage",          
                            "128GB HDD",                     "240GB SSD",                    
                            "8GB SSD",                       "508GB Hybrid",                 
                            "1000GB HDD",                     "1512GB SSD&Hybrid",    
                            "1256GB SSD&Hybrid"))

#find the memory type and set it as an attribute
dataset$MemoryType <- gsub(".*GB", "", dataset$Memory)

#find the memory size and set it as an attribute
dataset$MemorySize <- gsub("GB.*", "", dataset$Memory)

# remove Memory attribute to reduce redundency
dataset$Memory<-NULL

# Plot dataset based on MemoryType
ggplot(dataset, aes(x = MemoryType, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by Memory Type", x = "Memory Type", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plotting for the "MemorySize" variable
ggplot(dataset, aes(x = MemorySize, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0) +
  labs(title = "Jitter Plot of Laptop Prices by Memory Size", x = "Memory Size", y = "Price (in Euros)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


### Graphs

#### Product Histogram
##### Top 5 bought laptops are: XPS 13, EliteBook 840, IdeaPad Y700-15ISK, IdeaPad 320-15IAP, Blade Pro.
```{r}

#---
productHist <- table(dataset$Product)
productHist <- productHist[order(-productHist)]
barplot(productHist, main = "Frequency of Product", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)
```


#### Memory Sizes Histogram
##### Top 3 types of Memory Sizes are: 256GB, 1000GB, 500GB.
```{r}
#---
memorySizeHist <- table(dataset$MemorySize)
memorySizeHist <- memorySizeHist[order(-memorySizeHist)]
barplot(memorySizeHist, 
        main = "Frequency of Memory Size",
        ylab = "Frequency",
        las = 2, cex.names = 0.6)
```

#### Treemap

##### We used treemaps instead of pie chart to represent nominal data since most of our attributes have too many items. Pie chart would overlap our labels.

##### We can see all companies with thier details. "Dell" and "Lenovo" has equal percentage.
```{r}
# Calculate the frequency of each company
company_counts <- table(dataset$Company)
company_freq <- data.frame(Company = names(company_counts), Frequency = as.numeric(company_counts))
company_freq <- company_freq[order(company_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap <- plot_ly(
  company_freq,
  labels = ~Company,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap <- treemap %>%
  layout(title = "Company Frequency Treemap")
# print Company Treemap
treemap

```

##### We can see that around 50% of the laptops are "Notebook".
```{r}

# Calculate the frequency of each TypeName
type_counts <- table(dataset$TypeName)
type_freq <- data.frame(TypeName = names(type_counts), Frequency = as.numeric(type_counts))
type_freq <- type_freq[order(type_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap <- plot_ly(
  type_freq,
  labels = ~TypeName,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap <- treemap %>%
  layout(title = "TypeName Frequency Treemap")
# print TypeName Treemap
treemap
```

##### we can see that around 50% of the Ram are "8GB".
```{r}
# Calculate the frequency of each RAM category
ram_counts <- table(dataset$Ram)
ram_freq <- data.frame(Ram = names(ram_counts), Frequency = as.numeric(ram_counts))
ram_freq <- ram_freq[order(ram_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap <- plot_ly(
  ram_freq,
  labels = ~Ram,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap <- treemap %>%
  layout(title = "RAM Frequency Treemap")
# print Ram Treemap
treemap
```

##### we can see that Intel Core i7 >2, Intel Core i5 >2 take over 50% of the CPU.
```{r}
# Calculate the frequency of each CPU category
cpu_counts <- table(dataset$CategoryCPU)
cpu_freq <- data.frame(CategoryCPU = names(cpu_counts), Frequency = as.numeric(cpu_counts))
cpu_freq <- cpu_freq[order(cpu_freq$Frequency, decreasing = TRUE), ]
# Create a treemap
treemap_cpu <- plot_ly(
  cpu_freq,
  labels = ~CategoryCPU,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap_cpu <- treemap_cpu %>%
  layout(title = "CPU Category Frequency Treemap")
# Print CPU Treemap
treemap_cpu
```

##### Top 2 types of GPUs are: Intel HD Graphics is double the amount Nvidia GeForce Graphics. Both of them represent around 75% of the data.
```{r}
# Calculate the frequency of each GPU category
gpu_counts <- table(dataset$CategoryGPU)
gpu_freq <- data.frame(CategoryGPU = names(gpu_counts), Frequency = as.numeric(gpu_counts))
gpu_freq <- gpu_freq[order(gpu_freq$Frequency, decreasing = TRUE), ]

# Create a treemap
treemap_gpu <- plot_ly(
  gpu_freq,
  labels = ~CategoryGPU,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap_gpu <- treemap_gpu %>%
  layout(title = "GPU Category Frequency Treemap")
  
# Print GPU Category Treemap
treemap_gpu
```

##### We can see the Windows 10 system is over 75% .
```{r}
# Calculate the frequency of each OpSys
opsys_counts <- table(dataset$OpSys)
opsys_freq <- data.frame(OpSys = names(opsys_counts), Frequency = as.numeric(opsys_counts))
opsys_freq <- opsys_freq[order(opsys_freq$Frequency, decreasing = TRUE), ]
# Create a treemap for OpSys
treemap_opsys <- plot_ly(
  opsys_freq,
  labels = ~OpSys,
  parents = "",
  values = ~Frequency,
  type = "treemap",
  branchvalues = "total"
)
treemap_opsys <- treemap_opsys %>%
  layout(title = "OpSys Frequency Treemap")
# print OpSys Treemap
treemap_opsys
```


#### Bar chart

#### Company Bar chart and Histogram
##### Top 5 frequent companies were Dell, Lenovo, HP, Asus, Acer. For Dell, Lenovo, HP, Asus, we can notice that thier average price is around 1000€, which explains that their affordable prices is why it was from the seller companies. For Acer, it is around 500€, so its cheap price, made it preferable to people.
```{r}


#Company histogram
companyHist <- table(dataset$Company)
companyHist <- companyHist[order(-companyHist)]
barplot(companyHist, main = "Frequency of Company", 
        ylab = "Frequency",
        las = 2,cex.names = 0.8)

#Company Bar chart
dataset %>%
  group_by(Company) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(Company, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by Company", x = "Company", y = "Average Price for each company") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Ram Bar chart, jitter plot, and Histogram
##### Top 3 bought types of RAM are: 8GB,4GB,16GB. we can notice from the 3 graphs that 8GB is considered affordable(1250€<), 4GB(400€<) is considered Cheap, 16GB is considered Expensive(1250€>). This variety explains the difference of costumers preferances.

```{r}

#---------------
ramHist <- table(dataset$Ram)
ramHist <- ramHist[order(-ramHist)]
barplot(ramHist, main = "Frequency of RAM", 
        ylab = "Frequency",
        las = 2,cex.names = 0.8)
#---------------

# ram
dataset %>%
  group_by(Ram) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(Ram, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by RAM", x = "RAM", y = "Average Price for each RAM type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
#---------------
  ggplot(dataset, aes(x = Ram, y = Price_euros)) +
  geom_jitter(width = 0.2, height = 0, alpha = 0.5) +
  labs(title = "Jitter Plot of Price (in Euros) vs. RAM", x = "RAM", y = "Price (in Euros)") +
  theme_minimal()

```
#### Laptops types bar chart and Histogram

##### Top 3 boyght types of laptops are: Notebook, Gaming, Ultrabook. Notebook and Ultrabook which are the most bought type is considered affordable(1250€<), and for gaming it is considered Expensive(1250€>).

```{r}

#---
typeHist <- table(dataset$TypeName)
typeHist <- typeHist[order(-typeHist)]
barplot(typeHist, main = "Frequency of Type", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)


# typeName
dataset %>%
  group_by(TypeName) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(TypeName, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by TypeName", x = "TypeName", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

#### Operating system bar chart and Histogram

##### Top 3 types of Operating Systems are: Windows 10, No OS, Linux. Windows 10 is considered affordable(1250€<), this is explains why it is the top seller Operating system. No OS and Linux. can be described as cheap since thier price average is around 400€.
```{r}
# opSys
opSysHist <- table(dataset$OpSys)
opSysHist <- opSysHist[order(-opSysHist)]
barplot(opSysHist, main = "Frequency of Operating Systems", 
        ylab = "Frequency",
        las = 2,cex.names = 0.8)
#---
dataset %>%
  group_by(OpSys) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(OpSys, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by Operating system", x = "Operating System", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
#### CPU Category bar chart and Histogram

##### Top 3 types of CPUs are: Intel Core i7 >2, Intel Core i5 >2, Intel Core i3. From our results from the Jitter plot we can see that "Intel Core i3" can be described as "cheap", this explains why it was from the top 3 sellers. For "Intel Core i7 >2" and "Intel Core i5 >2" they had a large range, and represent more than 50% of the dataset, this explains why it was from the top 3.
##### "Intel Core i3" Average price is around 400€, this eplains why these tow are from the top sellers. For "Intel Core i5 >2" its Average price is 1000€, so we can describe it as affordable(1250€<). We can see that "Intel Core i7 >2" average price is larger than 1250, but we can not categorize it as Expensive, since it takes around 30% of the data, and has a large range of values.

```{r}
#CategoryCPU

#---
cpuHist <- table(dataset$CategoryCPU)
cpuHist <- cpuHist[order(-cpuHist)]
barplot(cpuHist, main = "Frequency of CPU", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)


dataset %>%
  group_by(CategoryCPU) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(CategoryCPU, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by CPU Category", x = "CPU Category", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### GPU Category bar chart and Histogram

##### "Intel HD Graphics" and "Nvidia GeForce Graphics" they had a large range in the jitter plot, so it has multible price options for customers. we can also see that "AMD Radeon Graphics which we described as Affordable (average price is 750 €) is from the top 3 sellers.
```{r}

#---
gpuHist <- table(dataset$CategoryGPU)
gpuHist <- gpuHist[order(-gpuHist)]
barplot(gpuHist, main = "Frequency of GPU", 
        ylab = "Frequency",
        las = 2,cex.names = 0.6)

#CategoryGPU
dataset %>%
  group_by(CategoryGPU) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(CategoryGPU, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by GPU Category", x = "GPU Category", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```
#### Memory Type bar chart and Histogram

##### Top 3 types of Memory Types are: SSD, HDD, SSD&HDD. SSD had a large range of values in the jitter plot, it offer a large variety of options, this explains why it is the most frequent product. "HDD" was in the cheaper range this is why it is the second most frequent product. For "HDD&SSD" it was categoreized as "Affordable" or "Expensive", so it was the 3rd frequent product.
```{r}

#-------------------
memoryTypeHist <- table(dataset$MemoryType)
memoryTypeHist <- memoryTypeHist[order(-memoryTypeHist)]
barplot(memoryTypeHist, main = "Frequency of Memory Type",
        ylab = "Frequency",
        las = 2, cex.names = 0.6)
#------------------

dataset %>%
  group_by(MemoryType) %>%
  summarize(Average_Price = mean(Price_euros, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(MemoryType, Average_Price), y = Average_Price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Average Laptop Prices by Memory Type", x = "Memory Type", y = "Average Price for each Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Normalization 

##### The price_euros attribute describe each laptop price’s in euros and since it has a huge values we normalized it and scaled it to be between the values 0 and 1 .
##### And since the inches attribute has a varying values, we also normalized it and scaled it to be between the values 0 and 1. And by taking this step it will help with handling and analyzing so that it would be understandable.
##### And we have another numeric data that needs to be normalized which is weight but before we normalize it, we need to remove the word “kg” and then transfer it to a numeric value instead of character which was done in a previous step, and then we normalize it to be between the values 0 and 1.
```{r}
 #Normalization 
  normalize = function(x) {return ((x-min(x)) / (max(x)))} 
  dataset$Price_euros = normalize(dataset$Price_euros)
  dataset$Inches = normalize(dataset$Inches)
  dataset$Weight = normalize(dataset$Weight)
```

### Feature Selection
##### we have the chi square for the nominal attributes ranked from the highest to the lowest : 
##### 1- Product
##### 2- Cpu 
##### 3- Screen resolution 
##### 4- Memory 
##### 5- Company 
##### 6- OpySys 
##### 7- Type name 

##### and we have the correlation for the numeric attributes ranked from the highest to the lowest :
##### 1- Ram 
##### 2- Weight 
##### 3- Inches 

##### since the product specify the brand, specifications, and features then the quality and performance of this product will have the highest effect on the price. 
##### for the cpu it has a great effect on the price of a laptop, Cpu's with higher performance and advanced technology tend to be more expensive, as they provide better performance and handle demanding tasks. So, the the more powerful a cpu a higher price for a laptop compared to one with less powerful Cpu. 
##### laptops with higher resolutions have a detailed display which can enhance the visual experience and this tend to make the price higher due to the cost of manufacturing and the improved viewing experience they offer. 
##### for the memory the higher memory allows for better multitasking, faster performance, and more storage space for files and applications which have a huge impact on the price of a laptop. 
##### for the other attributes which are OpySys, Type Name, and company all of them have an effect on the price but not as much as the previous attributes since they depend essentially on the product. 

##### for the numeric we have Ram, weight, and Inches. 
##### as the Ram is part of the memory then it has a huge impact on the price since it provides smoother multitasking so laptops with larger ram have a higher price. 
##### for the Weight and Inches it has an effect on the price but not as much as the Ram because they don't offer a new or enhanced features but generally smaller and lighter are more portable and convenient which can make them more expensive, on the other hand heavier laptops may have more room for additional components which can also increase the price. So, the Weight and Inches might play a role in determining the price of a laptop.

##### we don't have any redundant variables so, we didn't need to remove any attribute. 
```{r}
# Feature selection
result=chisq.test(dataset$Price_euros , dataset$Company)
print(result)
result=chisq.test(dataset$Price_euros , dataset$Product)
print(result)
result=chisq.test(dataset$Price_euros , dataset$TypeName)
print(result)
result=chisq.test(dataset$Price_euros , dataset$ScreenResolution)
print(result)
result=chisq.test(dataset$Price_euros , dataset$Cpu)
print(result)
result=chisq.test(dataset$Price_euros , dataset$Memory)
print(result)
result=chisq.test(dataset$Price_euros , dataset$OpSys)
print(result)


result2=cor(dataset$Price_euros ,dataset$Inches)
print(result2)
result2=cor(dataset$Price_euros ,dataset$Ram)
print(result2)
result2=cor(dataset$Price_euros ,dataset$Weight)
print(result2)

```

